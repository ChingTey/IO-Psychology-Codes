---
title: "Class 2 HW - ChingSiongTey"
output: html_notebook
---

# 1

Create a `parsnip` specification for a linear regression model.

*For future* run these library before start.
```{r echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}

#' <!-- #Loading libraries -->
suppressPackageStartupMessages({
library(broom)
library(corrr)
library(dials)
library(dplyr)
library(factoextra)
library(ggplot2)
library(glmnet)
library(infer)
library(ISLR)
library(kernlab)
library(kknn)
library(klaR)
library(MASS)
library(mclust)
library(modeldata)
library(paletteer)
library(parsnip)
library(patchwork)
library(proxy)
library(purrr)
library(randomForest)
library(readr)
library(recipes)
library(rpart)
library(rpart.plot)
library(rsample)
library(scico)
library(tibble)
library(tidymodels)
library(tidyr)
library(tidyverse)
library(tune)
library(vip)
library(workflows)
library(workflowsets)
library(xgboost)
library(yardstick)
library(conflicted)
library(discrim)
library(tidylog)
})

# From: https://rdrr.io/github/Bio302-UiB/data-handling/f/inst/tutorials/using-dplyr/using-dplyr.Rmd
# use purrr::map to iterate over tidylog functions to prevent conflict with dplyr
# map(getNamespaceExports("tidylog"), ~conflict_prefer(.x, "tidylog", quiet = TRUE))

for (f in getNamespaceExports("tidylog")) {
    conflicted::conflict_prefer(f, "tidylog", quiet = TRUE)
}

# Tidylog run through
# From: https://github.com/elbersb/tidylog/blob/master/README.Rmd


```


**Parsnip** helps us with model-fitting. Basically, with parsnip, we get to pre-define the specification of the model, which can be use to fit dataframe and variables later, so we don't have to keep typing the same regression instruction again and again.

# HW code
```{r}
lm_spec <- linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")
```
Here we are creating an object 'lm_spec' that will tell the computer to do linear regression


# 2

Once we have the specification we can `fit` it by supplying a formula expression and the data we want to fit the model on.
The formula is written on the form `y ~ x` where `y` is the name of the response and `x` is the name of the predictors.
The names used in the formula should match the names of the variables in the data set passed to `data`. 

Use `lm_spec` to fit the model of `medv` predicted by every predictor variable. Hint: you can use "." to specify every predictor.

# HW code

Let's see what's inside the dataframe first, so we can decide which predictor we want to use.
```{r}
summary(Boston)
```
The description of each variables can be found here https://r-data.pmagunia.com/dataset/r-dataset-package-mass-boston . It looks like other than "chas" (a Yes-No/1-0 dummy variable for Charles River), the rest are continuous variables.


```{r}
lm_fit <- lm_spec %>%       ## Here we are adding the ingredients (dataset and also the variables) to the spec object
  fit(medv ~ ., data = Boston)   ## the . here means everything else (variables).
lm_fit
```
We can see the coef here, but we can't tell if they are significant, and also some of the model characteristics.

# 3

Get a summary of your model using `pluck` and `summary`

# HW code
Use pluck and summary to get the fit info out of the fitted model
```{r}
lm_fit %>% 
  pluck("fit") %>%
  summary()
```

# 4

Take a look at `lm_fit` with `tidy`

# HW Code
tidy will create a tibble for listing the estimate and p-value of the model:
```{r}
tidy(lm_fit)
```

# 5

Extract the model statistics using `glance`

#HW code

Glance, different from tidy(), create a tibble for the bottom part of the summary() result. 
```{r}
glance(lm_fit)
```

# 6

Get the predicted `medv` values from your model using `predict`

Now we have drawn the line of best fit with this regression model, we can use this line to guess (predict) what the outcome (medv) could be using the predictors of a dataset. In this case, we will use the line of best fit from the lm_fit model on the predictors from Boston.

#HW code
```{r}
predict(lm_fit, new_data = Boston)
```


# 7

Bind the predicted columns to your existing data

#HW code
Now we can check if the prediction is good, by comparing it with the actual outcome from the Boston dataset.
```{r}
bind_cols(
  predict(lm_fit, new_data = Boston),
  Boston
) %>%
  select(medv, .pred)
```

# 8

Now, make things easier by just using the `augment` function to do this.

#HW code
The other way to add prediction column is via augment. In this way everything from both dataframe/object will be added together.
```{r}
augment(lm_fit, new_data = Boston)
```


# 9

Focus specifically on the median value and the `.pred`, then you can select those two columns

#HW code
Of course if we are not interested in the other data, we can just bind the true outcome (medv) and prediction together.
```{r}
augment(lm_fit, new_data = Boston) %>%
  select(medv, .pred)
```


# 10

Create a `recipe` with an interaction step between lstat and age

#HW code

Recipe is a function that let us not just specify a model, fit a data, but also prepare (transform) any variables via piping within the same chunk.
In this situation, let's ask the model to take into consideration of the interaction between lstat and age
```{r}
rec_spec <- recipe(medv ~ ., data = Boston) %>%
  step_interact(~ lstat:age)       ## the step_something command are the additional functions from recipe that allow us to add additional processing/transformation to the data.
```

# 11

Create a `workflow` and add your lm_spec model and your rec_spec recipe.

#HW code
Now we can push the recipe thru a workflow to see the result
```{r}
lm_wf <- workflow() %>%
  add_model(lm_spec) %>%    ## we still need to teach the workflow what model we are using
  add_recipe(rec_spec)    ## and the recipe. Later on when we fit the dataset into this workflow we also need to let it know the dataset is Boston
```

# 12

Fit your `workflow`.

#HW code
```{r}
lm_wf %>% fit(Boston)   # Now the new object is applying all the "rules" we added in the workflow to the Boston dataset.
```




